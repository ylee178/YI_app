{
  "run_id": "qa_2025-10-09T00:00:00Z",
  "analysis_type": "quantization_comparison",
  "models_evaluated": [
    {
      "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
      "quantization": "Q4_K_M",
      "file_size_mb": 1120,
      "bpw": 4.5,
      "source": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF"
    },
    {
      "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
      "quantization": "Q5_K_M",
      "file_size_mb": 1290,
      "bpw": 5.5,
      "source": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF"
    },
    {
      "model_id": "meta-llama/Llama-3.2-1B-Instruct",
      "quantization": "Q4_K_M",
      "file_size_mb": 808,
      "bpw": 4.5,
      "source": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF"
    }
  ],
  "kpi_comparison": {
    "qwen_2.5_1.5b_q4": {
      "file_size_mb": 1120,
      "mem_peak_mb": 2026,
      "ttft_ms": 150,
      "tok_s": 30,
      "mmlu_score": 48.5,
      "eq_projected": 85,
      "battery_drain_pct_10min": 2.0,
      "device_support": "6GB+"
    },
    "qwen_2.5_1.5b_q5": {
      "file_size_mb": 1290,
      "mem_peak_mb": 2298,
      "ttft_ms": 175,
      "tok_s": 26,
      "mmlu_score": 49.8,
      "eq_projected": 87,
      "battery_drain_pct_10min": 2.6,
      "device_support": "8GB+"
    },
    "llama_3.2_1b_q4": {
      "file_size_mb": 808,
      "mem_peak_mb": 1700,
      "ttft_ms": 130,
      "tok_s": 37,
      "mmlu_score": 49.3,
      "eq_projected": 87,
      "battery_drain_pct_10min": 1.6,
      "device_support": "4GB+"
    }
  },
  "gates": {
    "qwen_2.5_1.5b_q4": {
      "quality": "pass",
      "quality_margin": "marginal (EQ 85 gate)",
      "perf_ttft": "pass",
      "perf_decode": "pass",
      "stability": "pass",
      "device_reach": "pass (6GB+)"
    },
    "qwen_2.5_1.5b_q5": {
      "quality": "pass",
      "quality_margin": "safe (EQ 87 gate)",
      "perf_ttft": "marginal",
      "perf_decode": "pass",
      "stability": "pass",
      "device_reach": "fail (requires 8GB, target is 6GB)"
    },
    "llama_3.2_1b_q4": {
      "quality": "pass",
      "quality_margin": "safe (EQ 87 gate)",
      "perf_ttft": "pass",
      "perf_decode": "pass",
      "stability": "pass",
      "device_reach": "excellent (4GB+)"
    }
  },
  "issues": [
    {
      "id": "MM-001",
      "severity": "P1",
      "title": "Qwen 2.5 1.5B Q5_K_M requires 8GB RAM, excludes target 6GB devices",
      "evidence": "analysis_qwen_quantization_decision.md:Section 2 (Memory Analysis)",
      "fix": "Use Q4_K_M variant OR switch to Llama 3.2 1B which supports 4GB+",
      "status": "open",
      "model_affected": "Qwen2.5-1.5B Q5_K_M"
    },
    {
      "id": "MM-002",
      "severity": "P2",
      "title": "Qwen 2.5 1.5B Q4_K_M EQ score marginal (85, at gate threshold)",
      "evidence": "analysis_qwen_quantization_decision.md:Section 4 (Quality Analysis)",
      "fix": "Prompt engineering optimization OR upgrade to Q5_K_M with 8GB device requirement",
      "status": "open",
      "model_affected": "Qwen2.5-1.5B Q4_K_M"
    },
    {
      "id": "MM-003",
      "severity": "P1",
      "title": "PRD specifies Llama 3.2 1B as primary, Qwen not in scope",
      "evidence": "PRD.md:Line 13-15 (Primary: Llama 3.2 1B, Experimental: Gemma 1B)",
      "fix": "Validate Qwen adoption with stakeholder OR proceed with Llama 3.2 1B Q4_K_M per original plan",
      "status": "open",
      "model_affected": "All Qwen variants"
    }
  ],
  "recommendations": [
    {
      "id": "RF-001",
      "title": "PRIMARY: Use Llama 3.2 1B Q4_K_M instead of Qwen 2.5 1.5B",
      "diff": "models/llama3.2-1b/export_pte.py:+ Use bartowski/Llama-3.2-1B-Instruct-GGUF Q4_K_M (808MB)",
      "impact": "38% smaller download, 20% faster decode, 4GB device support (vs 6GB), proven ExecuTorch optimization",
      "priority": "HIGH"
    },
    {
      "id": "RF-002",
      "title": "ALTERNATIVE: If Qwen required, use Q4_K_M not Q5_K_M",
      "diff": "models/qwen2.5-1.5b/:+ Download Q4_K_M variant (1.12GB, 4.5bpw)",
      "impact": "170MB smaller, 15% faster decode, 6GB device support, $130/mo CDN savings per 10K users",
      "priority": "MEDIUM"
    },
    {
      "id": "RF-003",
      "title": "Implement adaptive preset system to maximize Q4_K_M quality",
      "diff": "app/presets.json:+ Add Safe preset (512 ctx, 128 max_new, temp 0.65) as default for 6GB devices",
      "impact": "Mitigate Q4_K_M quality gap with Q5_K_M, improve stability, reduce OOM risk",
      "priority": "HIGH"
    },
    {
      "id": "RF-004",
      "title": "Add EQ rubric testing before final model selection",
      "diff": "tools/eq_eval.py:+ Run 20-turn blind test on Llama Q4 vs Qwen Q4 vs Qwen Q5",
      "impact": "Data-driven decision instead of projection, validate 85+ EQ gate for chosen model",
      "priority": "CRITICAL"
    }
  ],
  "cost_analysis": {
    "cdn_monthly_10k_users": {
      "qwen_q4": {
        "cloudflare": 32,
        "aws": 850,
        "traffic_gb": 10640
      },
      "qwen_q5": {
        "cloudflare": 37,
        "aws": 980,
        "traffic_gb": 12255
      },
      "llama_q4": {
        "cloudflare": 24,
        "aws": 650,
        "traffic_gb": 7672
      }
    },
    "savings_llama_vs_qwen_q4": {
      "cloudflare": 8,
      "aws": 200,
      "annual_aws": 2400
    }
  },
  "device_compatibility": {
    "qwen_q4": {
      "iphone_12_4gb": false,
      "iphone_12_pro_6gb": true,
      "iphone_15_pro_8gb": true,
      "android_6gb": true,
      "android_8gb": true,
      "market_reach_pct": 70
    },
    "qwen_q5": {
      "iphone_12_4gb": false,
      "iphone_12_pro_6gb": false,
      "iphone_15_pro_8gb": true,
      "android_6gb": false,
      "android_8gb": true,
      "market_reach_pct": 40
    },
    "llama_q4": {
      "iphone_12_4gb": true,
      "iphone_12_pro_6gb": true,
      "iphone_15_pro_8gb": true,
      "android_6gb": true,
      "android_8gb": true,
      "market_reach_pct": 95
    }
  },
  "final_verdict": {
    "primary_recommendation": "Llama 3.2 1B Q4_K_M",
    "secondary_recommendation": "Qwen 2.5 1.5B Q4_K_M",
    "not_recommended": "Qwen 2.5 1.5B Q5_K_M",
    "rationale": [
      "Llama 3.2 1B Q4_K_M: Best overall - 38% smaller, 25% faster, 95% device reach, official ExecuTorch support",
      "Qwen 2.5 1.5B Q4_K_M: Valid if multilingual critical - 70% device reach, acceptable performance",
      "Qwen 2.5 1.5B Q5_K_M: Quality gain (+1.3 MMLU) not worth 40% market exclusion (8GB only)"
    ],
    "decision_pending": [
      "Run EQ rubric blind test on all 3 models (20 turns, 5 scenarios)",
      "Validate Qwen use case with stakeholder (PRD specifies Llama primary)",
      "Benchmark actual TTFT/tok/s on iPhone 12 Pro and Galaxy S21"
    ]
  },
  "trade_offs": {
    "if_qwen_q4_chosen": {
      "gains": [
        "1.5B params vs 1B = potentially more nuanced responses",
        "Better multilingual capability (Korean/Chinese/Japanese)",
        "Newer training data (2024 vs 2023)"
      ],
      "losses": [
        "38% larger download (1.12GB vs 0.81GB)",
        "25% slower decode (30 vs 37 tok/s)",
        "Excludes iPhone 12 4GB (30% of market)",
        "Less ExecuTorch optimization (community vs official)"
      ]
    },
    "if_qwen_q5_chosen": {
      "gains": [
        "+1.3 MMLU points vs Q4_K_M (49.8 vs 48.5)",
        "+2 EQ points projected (87 vs 85)",
        "Better context stability at 1024 tokens",
        "Lower hallucination rate in long responses"
      ],
      "losses": [
        "60% market exclusion (8GB only)",
        "15% slower performance",
        "22% higher battery drain",
        "$130/mo higher CDN cost (AWS, 10K users)",
        "Thermal throttling risk on 6GB devices"
      ]
    }
  },
  "next_steps": [
    {
      "step": 1,
      "action": "Export Llama 3.2 1B Q4_K_M to ExecuTorch PTE",
      "owner": "Senior Engineer Agent",
      "eta_hours": 2,
      "blockers": []
    },
    {
      "step": 2,
      "action": "Export Qwen 2.5 1.5B Q4_K_M to ExecuTorch PTE (parallel)",
      "owner": "Senior Engineer Agent",
      "eta_hours": 3,
      "blockers": [
        "May need custom export script (not in executorch/examples)"
      ]
    },
    {
      "step": 3,
      "action": "Device testing: iPhone 12 Pro, iPhone 15 Pro, Galaxy S21",
      "owner": "QA Engineer",
      "eta_hours": 48,
      "blockers": [
        "Need physical devices or cloud device farm access"
      ]
    },
    {
      "step": 4,
      "action": "EQ rubric blind test (20 turns, 5 scenarios, 3 models)",
      "owner": "QA/Research Assistant",
      "eta_hours": 72,
      "blockers": [
        "Requires models deployed to test harness"
      ]
    },
    {
      "step": 5,
      "action": "Final model selection decision",
      "owner": "Founder/Product Lead",
      "eta_hours": 96,
      "blockers": [
        "Awaits EQ test results + device benchmarks"
      ]
    }
  ],
  "metadata": {
    "generated_by": "QA/Research Assistant (Claude Code)",
    "sources": [
      "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF",
      "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF",
      "https://pytorch.org/blog/executorch-beta/",
      "llama.cpp GGUF quantization benchmarks",
      "Qwen official blog (qwenlm.github.io)",
      "Meta Llama 3.2 release docs"
    ],
    "estimation_methods": {
      "memory": "ExecuTorch admission formula (model_size × 1.6 + KV cache + 600MB overhead)",
      "performance": "Extrapolated from Llama 3.2 1B OnePlus 12 benchmarks (50.2 tok/s)",
      "quality": "MMLU delta from llama.cpp perplexity studies (Q8→Q5: -0.7, Q5→Q4: -1.3 pts)",
      "battery": "Mobile LLM power draw studies (6-8W inference, J/token = power × time)"
    },
    "assumptions": [
      "ExecuTorch XNNPACK backend (CPU inference)",
      "FP16 KV cache (2 bytes per activation)",
      "Safe preset: 512 context, 128 max_new_tokens",
      "iOS system overhead: 2.5-2.8GB on 6GB devices",
      "Android system overhead: 35-40% of total RAM",
      "CDN pricing: AWS CloudFront $0.08/GB (North America)",
      "User download pattern: 80% first install, 15% re-download, 5% A/B test"
    ],
    "confidence_levels": {
      "file_sizes": "HIGH (official Hugging Face data)",
      "memory_calculations": "MEDIUM (formula-based, not device-tested)",
      "performance_estimates": "MEDIUM (extrapolated from similar models)",
      "quality_scores": "LOW (projected, needs actual EQ testing)",
      "cost_analysis": "HIGH (based on published CDN pricing)"
    }
  }
}
