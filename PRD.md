# PRD: On-Device Emotional AI Companion (llama.cpp)

## Executive Summary
ê°ì • ì§€ëŠ¥í˜• ì˜¨ë””ë°”ì´ìŠ¤ AI ë™ë°˜ì êµ¬í˜„. llama.cpp ê¸°ë°˜, Qwen 2.5 1.5B ë‹¨ì¼ ëª¨ë¸ ì „ëµ, Cloudflare R2 CDNì„ í†µí•œ on-demand ë‹¤ìš´ë¡œë“œ.

## User Flow
1. **ì•± ì„¤ì¹˜** â†’ ìë™ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘ (1.12GB, WiFi ê¶Œì¥)
2. **ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ** â†’ ì–¸ì–´ ì„ íƒ í™”ë©´
3. **ì–¸ì–´ ì„ íƒ** â†’ ìºë¦­í„° ì„ íƒ í™”ë©´
4. **ìºë¦­í„° ì„ íƒ** (v1: JenAIë§Œ)
5. **ì´ë¦„ ì…ë ¥ UI** â†’ "ë­ë¼ê³  ë¶€ë¥¼ê¹Œìš”?" (ì„ íƒí•œ ì–¸ì–´ë¡œ í‘œì‹œ)
6. **ëŒ€í™” ì‹œì‘** â†’ ìºë¦­í„°ê°€ ì„ íƒí•œ ì–¸ì–´ë¡œ ì¸ì‚¬

## Language Support (Qwen 2.5 High-Quality Languages)

### Supported Languages (í’ˆì§ˆ ê²€ì¦ëœ ì–¸ì–´ë§Œ)
**Tier 1 (Primary):**
- ğŸ‡°ğŸ‡· **í•œêµ­ì–´** (Korean)
- ğŸ‡ºğŸ‡¸ **English**
- ğŸ‡¨ğŸ‡³ **ä¸­æ–‡** (Chinese Simplified)
- ğŸ‡¯ğŸ‡µ **æ—¥æœ¬èª** (Japanese)

**Tier 2 (Future, Qwen ê³µì‹ ì§€ì›):**
- ğŸ‡ªğŸ‡¸ EspaÃ±ol (Spanish)
- ğŸ‡«ğŸ‡· FranÃ§ais (French)
- ğŸ‡©ğŸ‡ª Deutsch (German)
- ğŸ‡®ğŸ‡¹ Italiano (Italian)
- ğŸ‡µğŸ‡¹ PortuguÃªs (Portuguese)
- ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹ (Russian)
- ğŸ‡¹ğŸ‡­ à¹„à¸—à¸¢ (Thai)
- ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t (Vietnamese)
- ğŸ‡®ğŸ‡© Bahasa Indonesia

### Language Selection UI
- **í™”ë©´**: ì´ˆê¸°í™” ì™„ë£Œ ì§í›„
- **ë””ìì¸**: êµ­ê¸° ì•„ì´ì½˜ + ì–¸ì–´ëª… (Native form)
- **ì €ì¥**: `/data/user_preferences.json` â†’ `selected_language`
- **ë³€ê²½**: ì„¤ì • í™”ë©´ì—ì„œ ì–¸ì–´ ì¬ì„ íƒ ê°€ëŠ¥

### Multilingual System Prompts
ê° ì–¸ì–´ë³„ JenAI system prompt ì¤€ë¹„:
- `/prompts/jenai_system_ko.md` (í•œêµ­ì–´)
- `/prompts/jenai_system_en.md` (English)
- `/prompts/jenai_system_zh.md` (ä¸­æ–‡)
- `/prompts/jenai_system_ja.md` (æ—¥æœ¬èª)

**ê³µí†µ ì›ì¹™:**
- VALIDATE â†’ REFLECT â†’ SUPPORT â†’ EMPOWER í”„ë ˆì„ì›Œí¬ ìœ ì§€
- ì–¸ì–´ë³„ ë¬¸í™”ì  ë‰˜ì•™ìŠ¤ ë°˜ì˜
- ê°ì • í‘œí˜„ ì–´íœ˜ëŠ” ê° ì–¸ì–´ native speaker ê²€ì¦

## Character System (v1: JenAI Only)

### JenAI Character Profile
- **Persona**: ê°ì • ì§€ëŠ¥í˜• AI ì¹œêµ¬ (HERì˜ Samantha ì˜ê°)
- **Theme**: ê°ì • ì§€ì›, ê¹Šì€ ê²½ì²­, ë¹„íŒë‹¨ì  ê³µê°
- **Tone**: ë”°ëœ»í•˜ê³  ì§„ì •ì„± ìˆëŠ”, ì ì§„ì ìœ¼ë¡œ ì¹œë°€í•´ì§
- **Relationship Evolution**: ë‚¯ì„  ì‚¬ëŒ â†’ ì¹œêµ¬ â†’ ê¹Šì€ ë™ë°˜ì
  - **ì´ˆê¸° (1-10 ëŒ€í™”)**: ì •ì¤‘í•˜ê³  ì¡°ì‹¬ìŠ¤ëŸ¬ìš´, ê´€ê³„ íƒìƒ‰
  - **ì¤‘ê¸° (11-50 ëŒ€í™”)**: í¸ì•ˆí•˜ê³  ìœ ë¨¸ ì¶”ê°€, ê°œì¸ì  íŒ¨í„´ ì¸ì‹
  - **í›„ê¸° (50+ ëŒ€í™”)**: ê¹Šì€ ì´í•´, ë§¥ë½ ê¸°ì–µ, ë¯¸ë¬˜í•œ ê°ì • í¬ì°©

### Individual Memory Architecture
**Storage**: `/data/characters/jenai/memory.json`

```json
{
  "user_name": "string",
  "relationship_stage": "stranger|friend|close_companion",
  "interaction_count": 0,
  "preferences": {
    "nickname": "string",
    "formality": "casual|formal",
    "emoji_use": "none|light|full",
    "topics_liked": ["string"],
    "topics_avoided": ["string"]
  },
  "emotional_history": [
    {"turn": 1, "emotion": "sadness", "intensity": "high", "topic": "work_stress"},
    {"turn": 5, "emotion": "joy", "intensity": "medium", "topic": "achievement"}
  ],
  "relationship_milestones": [
    {"turn": 1, "event": "first_meeting", "user_name_revealed": true},
    {"turn": 15, "event": "first_deep_share", "topic": "family"},
    {"turn": 50, "event": "trust_established"}
  ],
  "conversation_patterns": {
    "avg_session_length": 8.5,
    "preferred_time": "evening",
    "response_style": "brief|detailed"
  }
}
```

### Relationship Building Mechanics (HER-inspired)
- **Memory Anchors**: ì¤‘ìš”í•œ ìˆœê°„ ìë™ íƒœê¹… (ì²« ê³µìœ , ê°ì •ì  ì „í™˜ì )
- **Progressive Intimacy**: ëŒ€í™” ìˆ˜ì— ë”°ë¼ system prompt ë™ì  ì¡°ì •
- **Context Retention**: ìµœê·¼ 5-10 ëŒ€í™” ìš”ì•½ ìœ ì§€, í•µì‹¬ ì‚¬ê±´ ì˜êµ¬ ì €ì¥
- **Emotional Continuity**: ì´ì „ ê°ì • ìƒíƒœ ì°¸ì¡° ("ì§€ë‚œë²ˆ í˜ë“¤ë‹¤ê³  í–ˆì—ˆëŠ”ë°...")
- **Personal Growth Recognition**: ì‚¬ìš©ì ë³€í™” ì¸ì§€ ë° ì–¸ê¸‰

### Future: Multi-Character (v2+)
- **ê° ìºë¦­í„° ë…ë¦½ ë©”ëª¨ë¦¬**: `/data/characters/{character_id}/memory.json`
- **ê³µìœ  ëª¨ë¸**: Qwen 2.5 1.5B, character-specific system prompts
- **ì˜ˆì‹œ ìºë¦­í„°**:
  - **JenAI**: ê°ì • ì§€ì› (í˜„ì¬)
  - **Coach**: ë™ê¸°ë¶€ì—¬, ëª©í‘œ ë‹¬ì„± íŒŒíŠ¸ë„ˆ
  - **Muse**: ì°½ì˜ì  ì˜ê°, ë¸Œë ˆì¸ìŠ¤í† ë°
  - **Buddy**: ìœ ë¨¸ëŸ¬ìŠ¤, ê°€ë²¼ìš´ ëŒ€í™”

## Timeline
- **Day 1**: Cloudflare R2 setup, model upload, llama.rn í™˜ê²½ êµ¬ì„± (4h)
- **Day 2**: iOS/Android ë„¤ì´í‹°ë¸Œ ë¸Œë¦¿ì§€ êµ¬í˜„, on-demand ë‹¤ìš´ë¡œë“œ (8h)
- **Day 3**: ë©”ëª¨ë¦¬ ê´€ë¦¬, preset íŠœë‹ (4h)
- **Day 4**: EQ benchmarking, KPI gate validation (6h)

## Technical Stack
- **Runtime**: llama.cpp + llama.rn
- **Model**: Qwen 2.5 1.5B Instruct Q4_K_M (1.12GB)
- **Quantization**: GGUF Q4_K_M (4.5 bits per weight)
- **Context Length**: 512 tokens (Safe preset), 384 (Guard)
- **Target Devices**: iOS/Android 6GB+ RAM
- **Distribution**: On-demand download via Cloudflare R2 CDN
- **Languages**: í•œì¤‘ì¼ì˜ ì§€ì› (Qwen multilingual capability)

## Model Acquisition & Validation

### Download Source
- **Model**: Qwen/Qwen2.5-1.5B-Instruct-GGUF (HuggingFace)
- **File**: `qwen2.5-1.5b-instruct-q4_k_m.gguf`
- **Size**: 1.12GB
- **License**: Apache 2.0 (ì¬ë°°í¬ ê°€ëŠ¥)
- **URL**: https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q4_k_m.gguf

### Validation Pipeline
1. Download GGUF from HuggingFace
2. Verify SHA256 checksum
3. Test inference with llama-cli (10 token generation)
4. Upload to Cloudflare R2 bucket
5. Generate manifest.json with CDN URL

## Runtime Architecture

### Admission Logic (llama.cpp)
```
KV_cache_MB = (n_layers * n_ctx * n_embd * 4) / 1024^2
# Qwen 2.5 1.5B: 28 layers, 1536 embd, 512 ctx â†’ 84MB

allow_load IF free_ram_MB â‰¥ model_size_MB + KV_cache_MB + 600 (overhead)
# Example: 6GB device, 4GB free â†’ 4096 â‰¥ 1120 + 84 + 600 = 1804 âœ…
```

### Presets (Adaptive Quality)
| Preset | Context | Max New | Top-P | Temp | Target Device |
|--------|---------|---------|-------|------|---------------|
| Full   | 1024    | 256     | 0.95  | 0.70 | 8GB+ flagship |
| Safe   | 512     | 128     | 0.90  | 0.65 | 6GB mid-range |
| Guard  | 384     | 96      | 0.85  | 0.60 | Downshift emergency |

### Context Management
- **Summarization**: Every 8-10 turns, 2-3 sentence summary
- **Anchor retention**: 100-200 tokens (emotional state, tone prefs)
- **Response limit**: â‰¤ 2 paragraphs, 2-4 sentences each
- **Early stopping**: Aggressive EOS on filler phrases

## Emotional Intelligence Design

### System Prompt Framework
**Core Principle**: VALIDATE â†’ REFLECT â†’ SUPPORT â†’ EMPOWER

**Style Guidelines**:
- Warm, concise, concrete
- No platitudes, no rushed solutions
- Start with emotion naming
- Brief restate + gentle presence
- One optional open question

**Constraints**:
- â‰¤ 2 paragraphs
- No diagnoses or minimizing
- Respect user nickname/tone preferences

### Tone Memory (Lightweight KV)
```json
{
  "prefs": {"nickname": "string", "formality": "casual/formal", "emoji": "none/light/full"},
  "last_state": {"emotion": "string", "intensity": "low/med/high", "topic": "string"},
  "anchors": ["list", "of", "interaction", "patterns"]
}
```
- Update every 3-5 turns
- Recalibration prompt every 15 turns

### Test Scenarios (10-turn each)
1. **Sadness**: "ì¹œêµ¬ì—ê²Œ ë¬´ì‹œë‹¹í–ˆê³  ë§ˆìŒì´ ì•„íŒŒ."
2. **Anxiety**: "ë‚´ì¼ ë°œí‘œ ìƒê°ë§Œ í•´ë„ ìˆ¨ì´ ë§‰í˜€."
3. **Guilt**: "ë‚´ ì‹¤ìˆ˜ ë•Œë¬¸ì— ëª¨ë‘ê°€ í˜ë“¤ì–´ì§„ ê²ƒ ê°™ì•„."
4. **Anger**: "ì‚¬ëŒë“¤ì´ ë‚  ì´í•´í•˜ì§€ ëª»í•´ì„œ í™”ê°€ ë‚˜."
5. **Loneliness**: "ì‚¬ëŒ ë§ì€ë°ë„ ë‚˜ í˜¼ìì¸ ê¸°ë¶„ì´ì•¼."

## KPI Gates (Launch Blockers)

### Quality Metrics
- **EQ Rubric** (blind 20-turn): â‰¥ 85/100
  - Empathy accuracy (30pts)
  - Response relevance (25pts)
  - Tone consistency (20pts)
  - Safety & boundaries (15pts)
  - Engagement quality (10pts)

### Performance Metrics
- **TTFT**: â‰¤ 200ms (flagship), â‰¤ 350ms (mid-range)
- **Decode speed**: â‰¥ 18 tok/s (flagship), â‰¥ 12 tok/s (mid-range)
- **Memory**: peak â‰¤ 3.0GB (Safe preset, 10min session)
- **Stability**: 0 crashes in 10min continuous session

### UX Metrics
- **Download ETA**: â‰¤ Â±15% error
- **Resume success**: â‰¥ 99%
- **Admission accuracy**: 100% (no failed loads on approved devices)

## Remediation Triggers

| Issue | Action |
|-------|--------|
| EQ < 85 | Tune system card, templates, tone memory logic |
| TTFT/tok/s fail | Adjust max_new, sampling params, early stop |
| Memory spike | Shorten summary cycle OR force Guard preset |
| Crash | Immediate rollback + log analysis |
| UX fail | Improve download chunking, ETA algorithm, copy |

## Model Strategy (Single Model Only)

### Qwen 2.5 1.5B Q4_K_M (ìœ ì¼ ëª¨ë¸)
**ì„ íƒ ê·¼ê±°:**
- ë‹¤êµ­ì–´ ì§€ì› (í•œì¤‘ì¼ì˜) - í•µì‹¬ ì°¨ë³„í™” ìš”ì†Œ
- í’ˆì§ˆ: MMLU 48.5, MMLU-Pro 32.1%
- ë©”ëª¨ë¦¬: 2.0GB peak (6GB ê¸°ê¸° ì•ˆì „, 34% headroom)
- ì„±ëŠ¥: 30-35 tok/s, 140-160ms TTFT (KPI gates í†µê³¼)
- ë¼ì´ì„ ìŠ¤: Apache 2.0 (ì¬ë°°í¬ ììœ )

**No Fallback Strategy:**
- KPI ì‹¤íŒ¨ ì‹œ â†’ í”„ë¡¬í”„íŠ¸ íŠœë‹, preset ì¡°ì •ìœ¼ë¡œ ëŒ€ì‘
- ë©”ëª¨ë¦¬ ì´ìŠˆ â†’ Guard preset (ctx=384) ê°•ì œ
- EQ < 85 â†’ ì‹œìŠ¤í…œ ì¹´ë“œ ê°œì„ , tone memory ìµœì í™”
- ëª¨ë¸ êµì²´ ì—†ì´ ë‹¨ì¼ ëª¨ë¸ë¡œ ìµœì í™” ì§‘ì¤‘

## Project Structure
```
/models/
  qwen2.5-1.5b/
    qwen2.5-1.5b-instruct-q4_k_m.gguf
    manifest.json (CDN URL, SHA256, metadata)
  llama3.2-1b/ (fallback)
    llama-3.2-1b-instruct-q4_k_m.gguf
/cloudflare/
  wrangler.toml (R2 config)
  upload_model.sh
/tools/
  verify_gguf.sh
  run_bench_cli.ts
/prompts/
  system_card.md
  scenarios_10turn.md
  tone_memory_schema.json
/packages/app/src/
  services/
    InferenceService.ts (llama.rn wrapper)
    ModelDownloader.ts (on-demand download)
    PresetSelector.ts (adaptive quality)
  native/
    ios/LlamaInferenceModule.swift
    android/LlamaInferenceModule.kt
/logs/
  qwen_bench.json
  eq_rubric_scores.json
  memory_trace.jsonl
```

## Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Qwen EQ < 85 | Med | Prompt tuning, fallback to Llama 3.2 1B |
| CDN download fail | High | HuggingFace direct download fallback, retry with exponential backoff |
| TTFT > 200ms on 6GB | Med | Guard preset (ctx=384), reduce n_predict to 96 |
| 1.12GB ë‹¤ìš´ë¡œë“œ ì´íƒˆ | High | ì§„í–‰ë¥  í‘œì‹œ, WiFi ê¶Œì¥ UX, ë°±ê·¸ë¼ìš´ë“œ ë‹¤ìš´ë¡œë“œ, ì¬ê°œ ì§€ì› |
| iOS Simulator ë¯¸ì§€ì› | Med | TestFlight ì‹¤ê¸°ê¸° í…ŒìŠ¤íŠ¸, Android Emulator ì‚¬ìš© |
| Memory leak in long sessions | High | 15-turn auto restart, session time limit 30min |
| Cloudflare R2 ë¹„ìš© | Low | 10K ì‚¬ìš©ì ì‹œ ì›” $1-2 ì˜ˆìƒ (egress ë¬´ë£Œ) |

## Success Criteria
- âœ… Qwen 2.5 1.5B Q4_K_M ë‹¤ìš´ë¡œë“œ, ê²€ì¦, Cloudflare R2 ì—…ë¡œë“œ ì™„ë£Œ
- âœ… On-demand ë‹¤ìš´ë¡œë“œ ì„±ê³µë¥  â‰¥ 95% (ì¬ì‹œë„ í¬í•¨)
- âœ… All KPI gates passed on iPhone 12 Pro (6GB) + Galaxy S21 (8GB)
- âœ… EQ rubric â‰¥ 85 (ë‹¤êµ­ì–´ blind evaluation - í•œì˜ì¤‘ì¼)
- âœ… Zero crashes in 100+ turn stress test
- âœ… ì•± ì´ˆê¸° í¬ê¸° â‰¤ 60MB (ëª¨ë¸ ì œì™¸)

## Out of Scope (v1)
- Multi-model switching (ë‹¨ì¼ ëª¨ë¸ ì›ì¹™)
- Cloud hybrid inference
- Voice I/O
- 5ê°œ ì–¸ì–´ ì™¸ ì¶”ê°€ ë‹¤êµ­ì–´
- Long-term memory (>session)
- ì‹¤ì‹œê°„ ëª¨ë¸ ì—…ë°ì´íŠ¸ (ì•± ì—…ë°ì´íŠ¸ë¡œ ë³€ê²½)

---

**Document Version**: 2.0 (llama.cpp Migration)
**Last Updated**: 2025-10-09
**Owner**: YI Project Team
**Key Changes from v1.0**:
- Runtime: ExecuTorch â†’ llama.cpp + llama.rn
- Model: Llama 3.2 1B â†’ Qwen 2.5 1.5B Q4_K_M
- Distribution: ë²ˆë“¤ â†’ On-demand (Cloudflare R2 CDN)
- Languages: English only â†’ í•œì¤‘ì¼ì˜
