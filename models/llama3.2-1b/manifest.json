{
  "model_id": "bartowski/Llama-3.2-1B-Instruct-GGUF",
  "model_file": "/Users/uxersean/Desktop/YI_Clean/models/llama3.2-1b/Llama-3.2-1B-Instruct-Q8_0.gguf",
  "quantization": "Q8_0",
  "file_size_bytes": 1321083008,
  "file_size_gb": 1.23,
  "file_size_mb": 1259.9,
  "sha256": "432f310a77f4650a88d0fd59ecdd7cebed8d684bafea53cbff0473542964f0c3",
  "runtime": "llama.cpp",
  "backend": "CPU (ARM/x64 optimized)",
  "sequence_length": 512,
  "format": "GGUF",
  "optimizations": [
    "Q8_0 quantization (8-bit)",
    "Native GGUF format",
    "llama.cpp optimized"
  ]
}