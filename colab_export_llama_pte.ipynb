{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.2 1B → ExecuTorch PTE Export (Colab)\n",
    "\n",
    "**Steps**:\n",
    "1. Run all cells in order\n",
    "2. Download the `.pte` file when complete\n",
    "3. Verify with local tools\n",
    "\n",
    "**Runtime**: GPU (T4, 16GB RAM) recommended but CPU works\n",
    "**Time**: ~15-20 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1/6] Install ExecuTorch\n",
    "!git clone --depth 1 https://github.com/pytorch/executorch.git\n",
    "!cd executorch && pip install -r requirements.txt\n",
    "!cd executorch && pip install -e . --no-build-isolation\n",
    "\n",
    "print(\"✅ ExecuTorch installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2/6] Install dependencies\n",
    "!pip install transformers==4.43.* safetensors huggingface-hub psutil\n",
    "\n",
    "# Verify\n",
    "import executorch\n",
    "from executorch.exir import to_edge\n",
    "print(f\"✅ ExecuTorch {executorch.__version__} ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3/6] Clone YI_Clean project\n",
    "!git clone --depth 1 https://github.com/ylee178/YI_Clean.git\n",
    "!ls -lh YI_Clean/models/llama3.2-1b/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4/6] Optional: HuggingFace login (if Llama requires auth)\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Uncomment and add your token if needed:\n",
    "# login(token=\"hf_...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [5/6] Run Export\n",
    "import os\n",
    "os.chdir(\"/content/YI_Clean/models/llama3.2-1b\")\n",
    "\n",
    "!python export_pte.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [6/6] Verify & Download\n",
    "import glob\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "pte_files = glob.glob(\"*.pte\")\n",
    "assert pte_files, \"❌ No .pte files found!\"\n",
    "\n",
    "for pte in pte_files:\n",
    "    size_mb = os.path.getsize(pte) / (1024**2)\n",
    "    print(f\"✅ {pte}: {size_mb:.1f} MB\")\n",
    "    \n",
    "    # Download\n",
    "    files.download(pte)\n",
    "    \n",
    "# Download manifest if exists\n",
    "if os.path.exists(\"manifest.json\"):\n",
    "    files.download(\"manifest.json\")\n",
    "\n",
    "print(\"\\n✅ Download complete! Check your Downloads folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
